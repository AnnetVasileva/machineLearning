{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtfC6uPs0waj"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSVU1XSX1ScS",
        "outputId": "529166fe-e5e2-4c56-9db4-c595f2e9f1a8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA7Dp3vh1gvG"
      },
      "source": [
        "train_set = '/content/drive/MyDrive/ML_ECO/cup98lrn.csv' # zip\r\n",
        "valid_set = '/content/drive/MyDrive/ML_ECO/cup98val.csv'"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFhW3ltc1ZDy"
      },
      "source": [
        "df = pd.read_csv(train_set,low_memory = False)  #compression='zip'"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5yb3Dsga6uI"
      },
      "source": [
        "val = pd.read_csv(valid_set,low_memory = False)  #ASSUMING THE ORDER of columns is the same"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enUAV3Q9wduc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927a5785-a550-4874-b265-5b0f092280f2"
      },
      "source": [
        "df.columns[362:386] # just checking , should be ADATEs and RFA_2"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ADATE_2', 'ADATE_3', 'ADATE_4', 'ADATE_5', 'ADATE_6', 'ADATE_7',\n",
              "       'ADATE_8', 'ADATE_9', 'ADATE_10', 'ADATE_11', 'ADATE_12', 'ADATE_13',\n",
              "       'ADATE_14', 'ADATE_15', 'ADATE_16', 'ADATE_17', 'ADATE_18', 'ADATE_19',\n",
              "       'ADATE_20', 'ADATE_21', 'ADATE_22', 'ADATE_23', 'ADATE_24', 'RFA_2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auoS8TtkwCr_"
      },
      "source": [
        "## Preprosessing\n",
        "Our preprosessing will include 4 steps:\n",
        "1. We will delete the columns we will not use (please see documentation to see which columns we drop)\n",
        "2. Re-code /transform complex variables to easier ones\n",
        "3. Encode ordinal variables using ordinal encoder and create one-hot-encoding where ordinal encoding is not suitable\n",
        "4. Delete observations with missing data or additionally drop features that contain more than 50% of missing data\n",
        "\n",
        "After each step we will check whether our target variable (TARGET_B) still has enough positive examples (value = 1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMD82WM5fwr3"
      },
      "source": [
        "**STEP 1: Drop Features**\n",
        "\n",
        "In dropping features we follow certain rules, namely:\n",
        "1. We drop every feature that is a date\n",
        "2. We drop features that refer to the sources of information \n",
        "3. We drop features that are already covered implicitly by the other features that we will encode \n",
        "4. We drop features that have a very complex structure and would require a lot of dummy variables (like STATE)\n",
        "5. We drop features that highly depend on features that we previously decided to drop (like WEALTH2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7jT4Bi2wk2z"
      },
      "source": [
        "# some important stuff \n",
        "yesno_variables = df.columns[56:74]\n",
        "rfas = df.columns[386:408] # RFA variables"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHyXWO6VxEpx"
      },
      "source": [
        "drop1 = df.columns[1:15].to_list() # need to drop these\n",
        "drop2 = df.columns[16]#.to_list() # CLUSTER   \n",
        "drop3 = df.columns[18]#.to_list() # AGEFLAG\n",
        "drop4 = df.columns[44:51].to_list() # connection to the war and war veterans , might actually be relevant even though very specific data\n",
        "drop11 = df.columns[51:54].to_list() # SOLICIT variables + MAJOR\n",
        "drop5 = df.columns[54:56].to_list() \n",
        "drop6 = df.columns[362:386].to_list() # ADATES and RFA_XX\n",
        "drop7 = df.columns[413:457].to_list() # Dates of different donations received\n",
        "drop8 = df.columns[473]\n",
        "drop9 = df.columns[480:482].to_list() # CLUSTER and GEOCODE\n",
        "drop10 = df.columns[43] # drop the source from where the data is collected\n",
        "drop12 = df.columns[74] #  LIFE STYLE DATA SOURCE\n",
        "drop13 = df.columns[461] # Date associated with the smallest gift to date\n",
        "drop14 = df.columns[463] # Date associated with the largest gift to date\n",
        "drop15 = df.columns[465:468].to_list() # Dates of different gifts received\n",
        "drop16 = df.columns[409] # MAXADATE\n",
        "drop17 = df.columns[24] # Number of Children, very ambiguous since many empty cells, covered by other variables implicitly\n",
        "drop18 = df.columns[196:199] # these are very weird codes, I do not know how to use them for the prediction\n",
        "drop = drop1+drop5+drop6+drop7+drop9+drop11+drop15+drop4\n",
        "df = df.drop(drop, axis = 1)\n",
        "df = df.drop(drop2,axis = 1)\n",
        "df = df.drop(drop3, axis = 1)\n",
        "df = df.drop(drop8, axis = 1)\n",
        "df = df.drop(drop10, axis = 1)\n",
        "df = df.drop(drop12, axis = 1)\n",
        "df = df.drop(drop13, axis = 1)\n",
        "df = df.drop(drop14, axis = 1)\n",
        "df = df.drop(drop17, axis = 1)\n",
        "\n",
        "\n",
        "# repeat for val\n",
        "\n",
        "val = val.drop(drop, axis = 1)\n",
        "val = val.drop(drop2,axis = 1)\n",
        "val = val.drop(drop3, axis = 1)\n",
        "val = val.drop(drop8, axis = 1)\n",
        "val = val.drop(drop10, axis = 1)\n",
        "val = val.drop(drop12, axis = 1)\n",
        "val = val.drop(drop13, axis = 1)\n",
        "val = val.drop(drop14, axis = 1)\n",
        "val = val.drop(drop17, axis = 1)\n"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOFjVokF1_SG"
      },
      "source": [
        "**STEP 2 : Encode**\n",
        "\n",
        "Now we start encoding things\n",
        "1. We first rename the first column to Index\n",
        "2. We then extract the first letter from Domain to then encode it to one-hot encoding\n",
        "3. Afterwards we change the CHILDXX variables , which will be also encoded as one-hot \n",
        "4.\n",
        "5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96niBL_Axrty"
      },
      "source": [
        "df = df.rename(columns = {'Unnamed: 0' : 'Index'}) # rename first column to the Index\n",
        "val = val.rename(columns = {'Unnamed: 0' : 'Index'}) # rename first column to the Index\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFsSV8NFXgjx",
        "outputId": "2f3b2d49-6043-4133-d177-c5e9d842bc09"
      },
      "source": [
        "val.DOMAIN.unique()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['T1', 'C1', 'C2', 'R2', 'S1', 'C3', 'T2', 'U2', 'U1', 'U4', 'S2',\n",
              "       'S3', ' ', 'T3', 'R3', 'U3', 'R1'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qSvlAB7ljre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c6db7b-132c-4053-c913-abdc49525c00"
      },
      "source": [
        "df.DOMAIN = df.DOMAIN.replace({' ': '99'}) # replace empty cells to 99 and then every 9 will be replaced to NaN\n",
        "\n",
        "df['SES'] = 0 # NEW variable - socioeconomic status - second byte from DOMAIN\n",
        "index = 0\n",
        "for x in df.DOMAIN:\n",
        "    df.SES[index] = int(df.DOMAIN[index][1])\n",
        "    index += 1\n",
        "\n",
        "\n",
        "# extracting the first \n",
        "index = 0\n",
        "for x in df.DOMAIN:\n",
        "    df.DOMAIN[index] = df.DOMAIN[index][0]\n",
        "    index += 1\n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0kZ5uFbbhKB",
        "outputId": "f06989e3-7a64-425d-a38e-e79913c673c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val.DOMAIN = val.DOMAIN.replace({' ': '99'}) # replace empty cells to 99 and then every 9 will be replaced to NaN\n",
        "\n",
        "val['SES'] = 0 # NEW variable - socioeconomic status - second byte from DOMAIN\n",
        "index = 0\n",
        "for x in val.DOMAIN:\n",
        "    val.SES[index] = int(val.DOMAIN[index][1])\n",
        "    index += 1\n",
        "\n",
        "\n",
        "# extracting the first \n",
        "index = 0\n",
        "for x in val.DOMAIN:\n",
        "    val.DOMAIN[index] = val.DOMAIN[index][0]\n",
        "    index += 1"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8MFmbca3hYV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "8fc5676a-969b-4776-f6c6-1da23ef2b201"
      },
      "source": [
        "val[rfas]"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RFA_3</th>\n",
              "      <th>RFA_4</th>\n",
              "      <th>RFA_5</th>\n",
              "      <th>RFA_6</th>\n",
              "      <th>RFA_7</th>\n",
              "      <th>RFA_8</th>\n",
              "      <th>RFA_9</th>\n",
              "      <th>RFA_10</th>\n",
              "      <th>RFA_11</th>\n",
              "      <th>RFA_12</th>\n",
              "      <th>RFA_13</th>\n",
              "      <th>RFA_14</th>\n",
              "      <th>RFA_15</th>\n",
              "      <th>RFA_16</th>\n",
              "      <th>RFA_17</th>\n",
              "      <th>RFA_18</th>\n",
              "      <th>RFA_19</th>\n",
              "      <th>RFA_20</th>\n",
              "      <th>RFA_21</th>\n",
              "      <th>RFA_22</th>\n",
              "      <th>RFA_23</th>\n",
              "      <th>RFA_24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A2F</td>\n",
              "      <td>A2F</td>\n",
              "      <td>A1E</td>\n",
              "      <td>A1E</td>\n",
              "      <td>A2E</td>\n",
              "      <td>A2E</td>\n",
              "      <td>A2E</td>\n",
              "      <td>A2E</td>\n",
              "      <td>A2E</td>\n",
              "      <td>A1D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td></td>\n",
              "      <td>N2F</td>\n",
              "      <td>N1E</td>\n",
              "      <td>N1E</td>\n",
              "      <td>N1E</td>\n",
              "      <td>N1E</td>\n",
              "      <td>N1E</td>\n",
              "      <td>N1E</td>\n",
              "      <td>F1E</td>\n",
              "      <td>F1E</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>P1E</td>\n",
              "      <td>P1E</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td></td>\n",
              "      <td>A1F</td>\n",
              "      <td>N1D</td>\n",
              "      <td>N1D</td>\n",
              "      <td>N1D</td>\n",
              "      <td>N1D</td>\n",
              "      <td>N1D</td>\n",
              "      <td>N1D</td>\n",
              "      <td></td>\n",
              "      <td>F1D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3E</td>\n",
              "      <td>A3E</td>\n",
              "      <td></td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A3D</td>\n",
              "      <td>A2D</td>\n",
              "      <td></td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A2D</td>\n",
              "      <td>A1D</td>\n",
              "      <td>A1D</td>\n",
              "      <td>A1D</td>\n",
              "      <td></td>\n",
              "      <td>A1D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96362</th>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td></td>\n",
              "      <td>L1F</td>\n",
              "      <td>L1F</td>\n",
              "      <td>L1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td></td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>A1F</td>\n",
              "      <td>L2F</td>\n",
              "      <td></td>\n",
              "      <td>L2F</td>\n",
              "      <td>L2F</td>\n",
              "      <td></td>\n",
              "      <td>L2F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96363</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>L1E</td>\n",
              "      <td>A1E</td>\n",
              "      <td>A1E</td>\n",
              "      <td>A1E</td>\n",
              "      <td>A1E</td>\n",
              "      <td>A1E</td>\n",
              "      <td>A1E</td>\n",
              "      <td></td>\n",
              "      <td>A1E</td>\n",
              "      <td></td>\n",
              "      <td>A1E</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>A1D</td>\n",
              "      <td>A1D</td>\n",
              "      <td>A1D</td>\n",
              "      <td>A1D</td>\n",
              "      <td></td>\n",
              "      <td>A1D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96364</th>\n",
              "      <td>N2F</td>\n",
              "      <td>N2F</td>\n",
              "      <td>N2F</td>\n",
              "      <td>F1E</td>\n",
              "      <td>F1E</td>\n",
              "      <td>F1E</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>P1A</td>\n",
              "      <td>P1E</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96365</th>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>N3G</td>\n",
              "      <td>N3G</td>\n",
              "      <td>N3G</td>\n",
              "      <td>N3G</td>\n",
              "      <td>N2G</td>\n",
              "      <td>N2G</td>\n",
              "      <td>N2G</td>\n",
              "      <td>F1F</td>\n",
              "      <td>F1F</td>\n",
              "      <td>F1F</td>\n",
              "      <td>F1F</td>\n",
              "      <td></td>\n",
              "      <td>P1A</td>\n",
              "      <td>P1F</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96366</th>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A2G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>A1G</td>\n",
              "      <td>L2F</td>\n",
              "      <td>L2F</td>\n",
              "      <td>L2F</td>\n",
              "      <td>L2F</td>\n",
              "      <td></td>\n",
              "      <td>L2F</td>\n",
              "      <td>L2F</td>\n",
              "      <td></td>\n",
              "      <td>A1F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96367 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RFA_3 RFA_4 RFA_5 RFA_6 RFA_7  ... RFA_20 RFA_21 RFA_22 RFA_23 RFA_24\n",
              "0       A1G   A1G   A1G   A1G   A2G  ...    A2E    A2E    A2E    A2E    A1D\n",
              "1       A1F   A1F         N2F   N1E  ...                                   \n",
              "2       A1G   A1G   A1G   A1G   A1G  ...    A1F    A1F    A1F    A1F    A1F\n",
              "3       A1F   A1F   A1F   A1F   A1F  ...    N1D    N1D    N1D           F1D\n",
              "4       A3E   A3E         A2D   A2D  ...    A1D    A1D    A1D           A1D\n",
              "...     ...   ...   ...   ...   ...  ...    ...    ...    ...    ...    ...\n",
              "96362   A1F   A1F         L1F   L1F  ...           L2F    L2F           L2F\n",
              "96363                     L1E   A1E  ...    A1D    A1D    A1D           A1D\n",
              "96364   N2F   N2F   N2F   F1E   F1E  ...                                   \n",
              "96365   A1G   A1G   A2G   A2G   A2G  ...           P1A    P1F              \n",
              "96366   A1G   A1G   A2G   A2G   A2G  ...           L2F    L2F           A1F\n",
              "\n",
              "[96367 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9qZIfTJsHuc"
      },
      "source": [
        " df[rfas] = df[rfas].replace({' ': '999'})\n",
        " df['RFA_23'] = df['RFA_23'].replace({'1D': '91D','3E': '93E', '2D' : '92D', '1E': '91E', '1C': '91C', '1G': '91G', '2E': '92E',\n",
        "                                     '1F': '91F','4E': '94E', '3F': '93F' , '2F' : '92F', '1B': '91B'})\n",
        "  \n",
        "for item in rfas:\n",
        "    df[item + 'R'] = [ letter[0] for letter in df[item].to_list() ] # every first letter goes to Recency\n",
        "    df[item + 'F'] = [ int(letter[1]) for letter in df[item].to_list() ] # every second letter (actually integer) goes to Frequency\n",
        "    df[item + 'A'] = [ letter[2] for letter in df[item].to_list() ] # every third letter goes to Amount\n",
        "  \n",
        "for item in rfas:\n",
        "    df[item + 'R'] = df[item + 'R'].replace({'9': np.NaN, 'U': np.NaN, 'P': np.NaN})\n",
        "    df[item + 'F'] = df[item + 'F'].replace({9: np.NaN})\n",
        "    df[item + 'A'] = df[item + 'A'].replace({'9': np.NaN, 'U': np.NaN, 'P': np.NaN})\n",
        " "
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaqhH6Yjb3zm"
      },
      "source": [
        "val[rfas] = val[rfas].replace({' ': '999'})\n",
        "val['RFA_23'] = val['RFA_23'].replace({'1D': '91D','3E': '93E', '2D' : '92D', '1E': '91E', '1C': '91C', '1G': '91G', '2E': '92E',\n",
        "                                     '1F': '91F','4E': '94E', '3F': '93F' , '2F' : '92F', '1B': '91B', '2C': '92C', '2G': '92G'})\n",
        "  \n",
        "for item in rfas:\n",
        "    val[item + 'R'] = [ letter[0] for letter in val[item].to_list() ] # every first letter goes to Recency\n",
        "    val[item + 'F'] = [ int(letter[1]) for letter in val[item].to_list() ] # every second letter (actually integer) goes to Frequency\n",
        "    val[item + 'A'] = [ letter[2] for letter in val[item].to_list() ] # every third letter goes to Amount\n",
        "  \n",
        "for item in rfas:\n",
        "    val[item + 'R'] = val[item + 'R'].replace({'9': np.NaN, 'U': np.NaN, 'P': np.NaN})\n",
        "    val[item + 'F'] = val[item + 'F'].replace({9: np.NaN})\n",
        "    val[item + 'A'] = val[item + 'A'].replace({'9': np.NaN, 'U': np.NaN, 'P': np.NaN})\n",
        " "
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyu-c3Wpq4Cc"
      },
      "source": [
        "df.HOMEOWNR = df.HOMEOWNR.replace({'H': 1, 'U': 0, ' ': np.NaN})\n",
        "df['CHILD03'] = df['CHILD03'].replace({' ': 'N'}) # we will assume that no indication of \n",
        "# children means no children as a category\n",
        "df['CHILD07'] = df['CHILD07'].replace({' ': 'N'})\t\n",
        "df['CHILD12'] = df['CHILD12'].replace({' ': 'N'})\n",
        "df['CHILD18'] = df['CHILD18'].replace({' ': 'N'})\n",
        "#df.MAJOR = df.MAJOR.replace({'X': 1, ' ': 0})\n",
        "df.PEPSTRFL = df.PEPSTRFL.replace({'X': 1, ' ':0})\n",
        "df.DOMAIN = df.DOMAIN.replace({9 : np.NaN, '9': np.NaN})\n",
        "df.SES = df.SES.replace({9 : np.NaN, 4: 3}) # please read documentation, the decision was made to replace every 4 to 3 so that technically 3 will include \n",
        "# all lowest SES\n",
        "df.SES = df.SES.replace({3: 1, 1: 3}) # now we replace all 3 with 1 and all 1 with 3 so that we can decode it ordinally\n",
        "df.GENDER = df.GENDER.replace({'A': 'U', 'C': 'U', ' ': np.NaN, 'J' : 'U'})\n",
        "#df.MDMAUD_A = df.MDMAUD_A.replace({'X': np.NaN})\n",
        "df.MDMAUD_F = df.MDMAUD_F.replace({'X': np.NaN})\n",
        "\n",
        "for item in yesno_variables:\n",
        "    df[item] = df[item].replace({' ': 0, 'N':0, 'Y': 1}) # these data values are a bit ambiguous since some of them do not have real N so we assume\n",
        "    #that empty cells represent negative observations\n",
        "\n",
        "\n",
        "recency = df.columns[376:442].to_list()[0::3]\n",
        "frequency = df.columns[376:442].to_list()[1::3]\n",
        "amount = df.columns[376:442].to_list()[2::3]\n"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YB0HuUxdlsZ"
      },
      "source": [
        "val.HOMEOWNR = val.HOMEOWNR.replace({'H': 1, 'U': 0, ' ': np.NaN})\n",
        "val['CHILD03'] = val['CHILD03'].replace({' ': 'N'}) # we will assume that no indication of \n",
        "# children means no children as a category\n",
        "val['CHILD07'] = val['CHILD07'].replace({' ': 'N'})\t\n",
        "val['CHILD12'] = val['CHILD12'].replace({' ': 'N'})\n",
        "val['CHILD18'] = val['CHILD18'].replace({' ': 'N'})\n",
        "#df.MAJOR = df.MAJOR.replace({'X': 1, ' ': 0})\n",
        "val.PEPSTRFL = val.PEPSTRFL.replace({'X': 1, ' ':0})\n",
        "val.DOMAIN = val.DOMAIN.replace({9 : np.NaN, '9': np.NaN})\n",
        "val.SES = val.SES.replace({9 : np.NaN, 4: 3}) # please read documentation, the decision was made to replace every 4 to 3 so that technically 3 will include \n",
        "# all lowest SES\n",
        "val.SES = val.SES.replace({3: 1, 1: 3}) # now we replace all 3 with 1 and all 1 with 3 so that we can decode it ordinally\n",
        "val.GENDER = val.GENDER.replace({'A': 'U', 'C': 'U', ' ': np.NaN, 'J' : 'U'})\n",
        "#df.MDMAUD_A = df.MDMAUD_A.replace({'X': np.NaN})\n",
        "val.MDMAUD_F = val.MDMAUD_F.replace({'X': np.NaN})\n",
        "\n",
        "for item in yesno_variables:\n",
        "    val[item] = val[item].replace({' ': 0, 'N':0, 'Y': 1}) # these data values are a bit ambiguous since some of them do not have real N so we assume\n",
        "    #that empty cells represent negative observations\n",
        "\n",
        "\n",
        "recency_val = val.columns[376:442].to_list()[0::3]\n",
        "frequency_val = val.columns[376:442].to_list()[1::3]\n",
        "amount_val = val.columns[376:442].to_list()[2::3]"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCXbM8eDuchI"
      },
      "source": [
        "too_many_nas = [] # columns where we still have too many nans\n",
        "\n",
        "for item in df:\n",
        "    if df[item].isna().sum() > len(df)*0.4:\n",
        "      too_many_nas.append(str(item))\n",
        "\n",
        "df = df.drop(too_many_nas, axis = 1)\n",
        "df = df.drop('Index', axis = 1)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7dkXCMtd--y"
      },
      "source": [
        "too_many_nas_val = [] # columns where we still have too many nans\n",
        "\n",
        "for item in val:\n",
        "    if val[item].isna().sum() > len(df)*0.4:\n",
        "      too_many_nas_val.append(str(item))\n",
        "\n",
        "if too_many_nas_val != too_many_nas:\n",
        "  too_many_nas_val = too_many_nas\n",
        "else:\n",
        "    pass\n",
        "\n",
        "\n",
        "val = val.drop(too_many_nas_val, axis = 1)\n",
        "val = val.drop('Index', axis = 1)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcUjgd6Sen2e",
        "outputId": "363207df-e3a7-42ad-b9d9-2ab5e91a9167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "list(np.setdiff1d(df.columns,val.columns))"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['TARGET_B', 'TARGET_D']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAHK0IjEfXtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd8e702-4570-4bc3-9ceb-461b045e2c07"
      },
      "source": [
        "[df.DOMAIN.unique()] + [df.MDMAUD_A.unique()]"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['T', 'S', 'R', 'U', 'C', nan], dtype=object),\n",
              " array(['X', 'C', 'M', 'L', 'T'], dtype=object)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo8ZltXBg9IJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1887e12-b25d-4b01-8f69-6546264f7a5c"
      },
      "source": [
        "too_many_nas_val == too_many_nas "
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4oiuYMoJ2g9"
      },
      "source": [
        "# now we need to drop \n",
        "recency_dropped = list(set.intersection(set(too_many_nas), set(recency)))\n",
        "frequency_dropped = list(set.intersection(set(too_many_nas), set(frequency)))\n",
        "amount_dropped = list(set.intersection(set(too_many_nas), set(amount)))\n",
        "\n",
        "recency = list(np.setdiff1d(recency,recency_dropped))\n",
        "frequency = list(np.setdiff1d(frequency,frequency_dropped))\n",
        "amount = list(np.setdiff1d(amount,amount_dropped))\n",
        "\n",
        "freq = [[1.0,2.0,3.0,4.0]] *len(frequency)\n",
        "am = [['A', 'B', 'C', 'D', 'E', 'F', 'G']] * len(amount)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSKsED3TN1-_"
      },
      "source": [
        "# now we need to drop \n",
        "recency_dropped_val = list(set.intersection(set(too_many_nas_val), set(recency_val)))\n",
        "frequency_dropped_val = list(set.intersection(set(too_many_nas_val), set(frequency_val)))\n",
        "amount_dropped_val = list(set.intersection(set(too_many_nas_val), set(amount_val)))\n",
        "\n",
        "recency_val = list(np.setdiff1d(recency_val,recency_dropped_val))\n",
        "frequency_val = list(np.setdiff1d(frequency_val,frequency_dropped_val))\n",
        "amount_val = list(np.setdiff1d(amount_val,amount_dropped_val))\n",
        "\n",
        "freq = [[1.0,2.0,3.0,4.0]] *len(frequency)\n",
        "am = [['A', 'B', 'C', 'D', 'E', 'F', 'G']] * len(amount)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV012tJKOUYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf28726-61ba-4d1b-ed56-39cbd064c230"
      },
      "source": [
        "df[amount[0]]"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          E\n",
              "1          E\n",
              "2        NaN\n",
              "3        NaN\n",
              "4          D\n",
              "        ... \n",
              "95407    NaN\n",
              "95408    NaN\n",
              "95409      E\n",
              "95410      F\n",
              "95411      G\n",
              "Name: RFA_10A, Length: 95412, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gsKo9RgWXa6"
      },
      "source": [
        "**Step 3: One Hot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MYZUFWWWbS6"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "#dropna\n",
        "df = df.dropna()\n",
        "val = val.dropna()\n",
        "\n",
        "one_hot_encoding = ['DOMAIN', 'CHILD03','CHILD12','CHILD18', 'GENDER', 'MDMAUD_R'] #+ recency\n",
        "categorical_encoding = ['MDMAUD_A', 'SES', 'INCOME'] + frequency + amount\n",
        "categories = [[ 'X' ,'L', 'C', 'M', 'T'],\n",
        "              ['1','2','3'],\n",
        "              [1.,2.,3.,4.,5.,6.,7.]] + freq + am\n",
        "\n",
        "\n",
        "ordinal_encoder = OrdinalEncoder(categories = categories)\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "\n",
        "df_onehot = one_hot_encoder.fit_transform(df[one_hot_encoding])\n",
        "df_ordinal = ordinal_encoder.fit_transform(df[categorical_encoding])\n",
        "\n",
        "val_onehot = one_hot_encoder.fit_transform(val[one_hot_encoding])\n",
        "val_ordinal = ordinal_encoder.fit_transform(val[categorical_encoding])\n"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgbeFV8lgc5J"
      },
      "source": [
        "# TARGET VARIABLES\n",
        "label_binary = df['TARGET_B'].to_numpy() # 1/0 donated or not\n",
        "label_dollars = df['TARGET_D'].to_numpy() # how much donated\n",
        "\n",
        "\n",
        "columns = np.setdiff1d(df.columns,one_hot_encoding)\n",
        "columns = np.setdiff1d(df.columns,categorical_encoding)\n",
        "columns = np.setdiff1d(df.columns,['TARGET_B','TARGET_D','CONTROLN'])\n",
        "\n",
        "df = df[columns]\n",
        "\n",
        "controln = val['CONTROLN']\n",
        "columns = np.setdiff1d(val.columns,one_hot_encoding)\n",
        "columns = np.setdiff1d(val.columns,categorical_encoding)\n",
        "columns = np.setdiff1d(val.columns,['CONTROLN'])\n",
        "\n",
        "\n",
        "val = val[columns]"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR1H343AUEyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2733cfed-7d04-4ca2-dfe3-9a0efc54d902"
      },
      "source": [
        "(label_dollars>0).sum()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "757"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0e3zWm8h6Pr"
      },
      "source": [
        "df = np.concatenate((df,df_onehot.toarray(), df_ordinal), axis = 1)\n",
        "val = np.concatenate((val,val_onehot.toarray(), val_ordinal), axis = 1)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9BuWbn0Sgym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008c6f71-2d40-48de-c92e-fb16d9a6ac87"
      },
      "source": [
        "df#.shape\n",
        "#label_binary.shape"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 11, 127.0, ..., 3.0, 4.0, 4.0],\n",
              "       [2, 3, 201.0, ..., 4.0, 4.0, 4.0],\n",
              "       [5, 6, 127.0, ..., 6.0, 6.0, 6.0],\n",
              "       ...,\n",
              "       [5, 6, 211.0, ..., 4.0, 4.0, 4.0],\n",
              "       [6, 3, 13.0, ..., 5.0, 5.0, 5.0],\n",
              "       [7, 4, 355.0, ..., 6.0, 6.0, 6.0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDFDRx_jjU5l",
        "outputId": "750f82fc-9e47-4070-da35-b9aa50433ddb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "controln"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        155244\n",
              "7         80803\n",
              "10       182234\n",
              "11       156420\n",
              "20       157437\n",
              "          ...  \n",
              "96333    132493\n",
              "96339     68028\n",
              "96343     21610\n",
              "96346      1040\n",
              "96350     59970\n",
              "Name: CONTROLN, Length: 15776, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejAnC9zhYao-"
      },
      "source": [
        "# FINAL RESULT SHOULD BE df and two labels\n",
        "import pickle\n",
        "data = {}\n",
        "data['X'] = val\n",
        "#data['y'] = label_binary\n",
        "data['CONTROLN'] = controln\n",
        "pickle_path = '/content/drive/MyDrive/ML_ECO/validation_set.pkl'\n",
        "with open(pickle_path, \"wb\") as f:\n",
        "    pickle.dump(data, f)"
      ],
      "execution_count": 180,
      "outputs": []
    }
  ]
}